# ç”¨VS Codeå®ç°Pythonè¿œç¨‹ä¸»æœºç¼–ç¨‹

**è¿æ¥è¿œç¨‹ä¸»æœºï¼š**

(1) è¿›å…¥æ‰©å±•å¸‚åœºï¼Œå®‰è£…Remote-SSH

(2) ç‚¹å‡»å·¦ä¸‹è§’çš„è¿œç¨‹è¿æ¥å›¾æ ‡ï¼Œé€‰æ‹©Connect to Host-Add New SSH Hostå¼€å§‹é…ç½®SSHè¿æ¥

![Alt Text](.\images\image-20250115104354113.png)

(3) SSHè¿æ¥å‘½ä»¤çš„æ ¼å¼ï¼š

```
ssh username@hostname -p port
```

å°†usernameã€hostnameï¼ˆæˆ–è€…IPï¼‰å’Œportæ›¿æ¢ä¸ºå®é™…å€¼ï¼Œæ¯”å¦‚

```
ssh mickey@123.123.0.123 -p 100
```

æŒ‰ä¸‹å›è½¦åï¼ŒVSCodeä¼šæç¤ºä½ ä¿å­˜è¿™äº›ä¿¡æ¯åˆ°é…ç½®æ–‡ä»¶ï¼ˆé€šå¸¸ä½äº`~/.ssh/config`æˆ–`C:\Users\your_username\.ssh\config`ï¼‰ï¼Œè¿™æ˜¯æ–¹ä¾¿ä»¥åå¿«é€Ÿè¿æ¥ï¼›ç„¶åè¾“å…¥å¯†ç å®Œæˆè¿æ¥

**æŠ¥é”™æç¤ºï¼š**å¦‚æœè¾“å…¥äº†é”™è¯¯çš„sshå‘½ä»¤ï¼Œå¹¶ä¿å­˜åˆ°configï¼Œé‚£ä¹ˆä¸‹ä¸€æ¬¡è¾“å…¥æ­£ç¡®å‘½ä»¤ä»¥åä»ç„¶æœ‰å¯èƒ½æ— æ³•è¿æ¥ï¼Œå› ä¸ºé…ç½®ä¿¡æ¯é”™è¯¯ã€‚æŠ¥é”™ä¿¡æ¯é‡Œä¼šç»™å‡ºé”™è¯¯ä¿¡æ¯ï¼Œä¾‹å¦‚

```
[08:46:43.726] > ]0;C:\WINDOWS\System32\cmd.exeC:\\Users\\admin/.ssh/config line 29: Bad port '-22'.
> C:\\Users\\admin/.ssh/config: terminating, 1 bad configuration options
```

è¯´æ˜ç«¯å£ä¿¡æ¯`22`é”™å†™ä¸º`-22`ï¼Œéœ€è¦åšçš„å°±æ˜¯æ‰“å¼€configä¿®æ”¹ä¹‹ã€‚

**è¿æ¥ä»¥åï¼š**

(1) æŸ¥çœ‹ç³»ç»Ÿç‰ˆæœ¬

```
uname -a
```

(2) å®‰è£…pythonå’Œminicondaï¼ˆæ ¹æ®ç³»ç»Ÿç‰ˆæœ¬é€‰æ‹©ï¼‰

```
# ä¸‹è½½å®‰è£…è„šæœ¬
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
# ç”¨bashæ‰§è¡Œåˆšæ‰å®‰è£…çš„ä¸‹è½½è„šæœ¬
bash Miniconda3-latest-Linux-x86_64.sh
```

(3) å®‰è£…pythonå’Œjupyteræ‰©å±•ï¼ˆæ‰©å±•å•†åº—ï¼‰

(4) æŠŠcondaå‘½ä»¤æ·»åŠ åˆ°ç¯å¢ƒå˜é‡ä¸­

```
export PATH=~/miniconda3/bin:$PATH
```

(5) å®‰è£…`ipykernel`ï¼šä¸€ä¸ªå…è®¸ä½ åœ¨ Jupyter ç¬”è®°æœ¬å’Œå…¶ä»– IPython å‰ç«¯ä¸­ä½¿ç”¨ Python å†…æ ¸çš„åŒ…

```
conda install ipykernel --update-deps --force-reinstall
```

(6) åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒ`diffusion`

```
# åˆ›å»ºç¯å¢ƒ
conda create -n diffusion python=3.10
# æ¿€æ´»ç¯å¢ƒ
conda activate diffusion
# éªŒè¯å½“å‰ç¯å¢ƒ
conda info --envs  # æˆ– conda env list  # æŸ¥çœ‹æ‰€æœ‰ç¯å¢ƒï¼Œå½“å‰ç¯å¢ƒä¼šæœ‰æ˜Ÿå·æ ‡è®°
```

(7) å¦‚æœä¸‹è½½å¢™å¤–ç½‘ç«™ï¼Œå¯ä»¥æ‰¾é•œåƒæºæ›¿ä»£ä¸‹è½½åœ°å€ï¼Œä¾‹å¦‚å°† huggingface.co æ”¹ä¸º hf-mirror.com. 

æ³¨æ„ï¼Œæœ‰æ—¶å€™ç›´æ¥æ›¿æ¢æºä¸å¥½æ“ä½œï¼Œä¾‹å¦‚ä¸‹ä¸€æ®µä»£ç ï¼ˆè°ƒç”¨æ¨¡å‹é»˜è®¤é‡‡ç”¨åŸé“¾æ¥ï¼‰ï¼š

```python
from diffusers import StableDiffusionPipeline
import torch

model_id = "SfinOe/stable-diffusion-v1.5"
pipe = StableDiffusionPipeline.from_pretrained(
    model_id, 
    torch_dtype=torch.float16,
    safety_checker=None  # å¯é€‰ï¼šå¦‚æœé‡åˆ°safety checkerç›¸å…³é”™è¯¯
)
pipe = pipe.to("cuda")

prompt = "A photo of a professor teaching machine learning in a bright, modern classroom"
image = pipe(prompt).images[0]  
    
image.save("professor_teach_ML.png")
```

ç”±äºæ¨¡å‹è°ƒç”¨çš„è¿‡ç¨‹ä¸­ä¼šé»˜è®¤ç”¨åŸåœ°å€ï¼Œè€Œä¸”å±‚å±‚è°ƒç”¨æ¯”è¾ƒéš¾æ‰¾åˆ°ä½¿ç”¨é“¾æ¥çš„å…·ä½“ä½ç½®ï¼Œä»è€Œéš¾ä»¥è¿›è¡Œé•œåƒæ›¿æ¢ï¼Œæ‰€ä»¥æ”¹ä¸ºç°åœ¨æœ¬åœ°ä¸‹è½½æ¨¡å‹ï¼Œç„¶åä»æœ¬åœ°è°ƒç”¨æ¨¡å‹ã€‚

å…ˆåœ¨å‘½ä»¤è¡Œä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ï¼š

```
# è®¾ç½®ç¯å¢ƒå˜é‡
export HF_ENDPOINT=https://hf-mirror.com

# ä½¿ç”¨ huggingface-cli ä»é•œåƒä¸‹è½½
huggingface-cli download --resume-download SfinOe/stable-diffusion-v1.5 --local-dir /root/.cache/huggingface/hub/models--SfinOe--stable-diffusion-v1-5
```

æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸‹è½½åˆ°æœ¬åœ°ï¼š

```python
import os

# æ£€æŸ¥é»˜è®¤çš„ huggingface ç¼“å­˜ç›®å½•
cache_dir = "/root/.cache/huggingface/hub/"
model_dir = os.path.join(cache_dir, "models--SfinOe--stable-diffusion-v1-5")

def check_model_cache():
    print(f"æ£€æŸ¥ç¼“å­˜ç›®å½•: {model_dir}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_dir):
        print("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
        return
    
    print("âœ“ æ¨¡å‹ç›®å½•å­˜åœ¨")
    
    # åˆ—å‡ºç›®å½•å†…å®¹
    print("\nç›®å½•å†…å®¹:")
    for root, dirs, files in os.walk(model_dir):
        level = root.replace(model_dir, '').count(os.sep)
        indent = ' ' * 4 * level
        print(f"{indent}{os.path.basename(root)}/")
        subindent = ' ' * 4 * (level + 1)
        for f in files:
            print(f"{subindent}{f}")

check_model_cache()
```

ç„¶åç›´æ¥ç”¨æœ¬åœ°æ–‡ä»¶å³å¯

```python
from diffusers import StableDiffusionPipeline
import torch

# ç›´æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„
local_model_path = "/root/.cache/huggingface/hub/models--SfinOe--stable-diffusion-v1-5"

pipe = StableDiffusionPipeline.from_pretrained(
    local_model_path,
    torch_dtype=torch.float16,
    safety_checker=None,
    local_files_only=True  # å¼ºåˆ¶åªä½¿ç”¨æœ¬åœ°æ–‡ä»¶
)
pipe = pipe.to("cuda")

prompt = "A photo of a professor teaching machine learning in a bright, modern classroom"
image = pipe(prompt).images[0]  
    
image.save("professor_teach_ML.png")
```

